# ==============================================================================
# PANELIN IMPROVEMENT GUIDE
# Guía para AI agents que mejoren el sistema Panelin
# ==============================================================================
#
# Este archivo documenta los principios arquitectónicos, patrones de código,
# y directrices para cualquier agente de IA que modifique el sistema.
#
# PRINCIPIO FUNDAMENTAL: LLM orquesta, código calcula.
# ==============================================================================

version: "2.0.0"
last_updated: "2026-01-28"
author: "BMC Uruguay / Panelin Team"

# ==============================================================================
# PRINCIPIOS ARQUITECTÓNICOS
# ==============================================================================
architecture_principles:
  
  LLM_NEVER_CALCULATES:
    description: "Todo cálculo matemático debe ejecutarse en funciones Python con tipo Decimal"
    rationale: |
      Los LLMs no garantizan precisión matemática del 100%. GPT-4o alcanza ~73% en
      benchmarks de cálculos complejos. Para cotizaciones financieras, necesitamos
      100% de precisión, por lo que TODA la aritmética ocurre en código Python
      usando el tipo Decimal para evitar errores de floating point.
    enforcement:
      - "Todas las funciones de cálculo deben retornar calculation_verified: True"
      - "Validación automática verifica que este campo sea True"
      - "Tests fallan si calculation_verified es False"
    
  SINGLE_SOURCE_OF_TRUTH:
    description: "panelin_truth_bmcuruguay.json es la única fuente de precios"
    rationale: |
      Múltiples fuentes de datos causan inconsistencias. Un solo archivo JSON
      versionado en Git proporciona:
      - Trazabilidad completa de cambios
      - Sincronización automática con Shopify
      - Auditabilidad para debugging
    enforcement:
      - "Todas las funciones de cálculo cargan precios de este archivo"
      - "Nunca hardcodear precios en código"
      - "Shopify webhooks actualizan este archivo automáticamente"
    
  DETERMINISTIC_FIRST:
    description: "Preferir herramientas deterministas sobre razonamiento LLM"
    rationale: |
      El LLM debe usarse solo para:
      - Comprensión de lenguaje natural
      - Extracción de parámetros del usuario
      - Formateo de respuestas
      
      El LLM NO debe usarse para:
      - Cálculos matemáticos
      - Lookup de precios
      - Decisiones de negocio
    enforcement:
      - "Definir herramientas @tool para cada operación determinista"
      - "El LLM solo llama herramientas, no calcula directamente"
      
  VALIDATE_EVERYTHING:
    description: "Cada output de cálculo debe pasar por verificación"
    rationale: |
      Doble verificación garantiza integridad:
      1. Checksum de resultado para detectar modificaciones
      2. Validación matemática (suma de líneas = subtotal)
      3. Verificación de rangos (precios > 0, descuentos < 30%)
    enforcement:
      - "validate_quotation() se llama después de cada calculate_panel_quote()"
      - "Tests verifican que todas las cotizaciones pasen validación"

# ==============================================================================
# MODIFICACIONES DE ARCHIVOS
# ==============================================================================
file_modifications:
  
  kb_training_system:
    action: "CONSOLIDATE"
    target: "panelin_truth_bmcuruguay.json"
    instructions: |
      - Eliminar archivos KB duplicados
      - Migrar todos los precios a formato estandarizado
      - Agregar campo 'calculation_rules' por producto
      - Incluir 'last_sync' timestamp en cada producto
    do_not:
      - "Crear nuevos archivos KB separados"
      - "Mantener precios en múltiples ubicaciones"
  
  gpt_consolidation_agent:
    action: "SIMPLIFY"
    instructions: |
      - Reducir a single-agent architecture
      - Convertir sub-agents a tool functions
      - Implementar structured output para extracción
      - Agregar validation layer post-extraction
    do_not:
      - "Crear múltiples agentes que se comunican entre sí"
      - "Permitir que agentes calculen directamente"
  
  calculation_functions:
    action: "CREATE/MODIFY"
    location: "panelin/tools/quotation_calculator.py"
    instructions: |
      - Usar Decimal para toda aritmética financiera
      - Incluir type hints completos (TypedDict returns)
      - Cargar precios desde JSON KB, nunca hardcodear
      - Agregar 'calculation_verified: True' en outputs
      - Implementar unit tests para cada función
    do_not:
      - "Usar float para cálculos de dinero"
      - "Hardcodear precios o descuentos"
      - "Retornar calculation_verified: False"

# ==============================================================================
# PATRONES DE CÓDIGO
# ==============================================================================
code_patterns:
  
  tool_definition: |
    # Ejemplo de herramienta correcta
    from langchain_core.tools import tool
    from decimal import Decimal, ROUND_HALF_UP
    
    @tool
    def calculate_panel_quote(
        panel_type: Literal["Isopanel EPS", "Isodec EPS", "Isodec PIR", 
                            "Isowall PIR", "Isoroof 3G", "Isoroof Plus 3G",
                            "Isoroof Foil 3G", "Hiansa Panel 5G"],
        thickness_mm: int,
        length_m: float,
        width_m: float, 
        quantity: int,
        discount_percent: float = 0.0
    ) -> QuotationResult:
        """Cálculo determinista - LLM solo extrae parámetros"""
        # Cargar precios desde KB (nunca hardcodear)
        catalog = load_knowledge_base()
        
        # Usar Decimal para precisión
        price = Decimal(str(catalog[product_key]["price_per_m2"]))
        area = Decimal(str(length_m)) * Decimal(str(width_m))
        total = (area * price * quantity).quantize(Decimal('0.01'), ROUND_HALF_UP)
        
        return QuotationResult(
            # ... campos ...
            calculation_verified=True,  # SIEMPRE True para código determinista
        )
  
  llm_configuration: |
    # Configuración óptima para precisión en extracción
    from langchain_openai import ChatOpenAI
    
    llm = ChatOpenAI(
        model="gpt-4o-mini",  # Costo óptimo para extracción
        temperature=0,        # Determinismo
        model_kwargs={
            "response_format": {"type": "json_object"}  # Structured output
        }
    )
    
    # Bind tools para function calling
    llm_with_tools = llm.bind_tools([
        calculate_panel_quote,
        lookup_product_specs,
        validate_quotation,
    ])
  
  validation_pattern: |
    # Verificación post-cálculo
    def validate_quotation(result: QuotationResult) -> ValidationResult:
        errors = []
        
        # Check 1: Debe ser calculado por código, no LLM
        if not result.get("calculation_verified"):
            errors.append("CRITICAL: calculation_verified is False")
        
        # Check 2: Checksum debe coincidir
        expected_checksum = generate_checksum(result)
        if result["verification_checksum"] != expected_checksum:
            errors.append("Checksum mismatch")
        
        # Check 3: Suma de líneas = subtotal
        line_sum = sum(item["line_total_usd"] for item in result["line_items"])
        if abs(line_sum - result["subtotal_usd"]) > 0.01:
            errors.append("Line items don't sum to subtotal")
        
        # Check 4: Precios positivos
        if result["total_usd"] <= 0:
            errors.append("Total must be positive")
        
        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
        )
  
  shopify_sync_pattern: |
    # Sincronización con Shopify vía webhooks
    async def handle_shopify_webhook(topic: str, payload: dict):
        """Actualiza KB cuando Shopify cambia."""
        
        # 1. Validar HMAC del webhook
        if not verify_webhook_signature(payload, hmac_header):
            raise SecurityError("Invalid webhook signature")
        
        # 2. Transformar datos
        kb_data = transform_shopify_to_kb(payload)
        
        # 3. Actualizar KB
        catalog = load_knowledge_base()
        catalog["products"][product_key] = kb_data
        catalog["last_sync"] = datetime.utcnow().isoformat()
        
        # 4. Guardar (con timestamp para audit)
        save_knowledge_base(catalog)
        
        # 5. Log evento
        log_sync_event(topic, product_key, "success")

# ==============================================================================
# REQUISITOS DE TESTING
# ==============================================================================
testing_requirements:
  
  minimum_golden_tests: 50
  coverage_threshold: 95
  
  required_test_categories:
    basic_calculations:
      description: "Tests de cálculos básicos por tipo de panel"
      examples:
        - "test_basic_isopanel_quote"
        - "test_isodec_eps_100mm_quote"
        - "test_isoroof_3g_quote"
    
    discount_applications:
      description: "Tests de aplicación de descuentos"
      examples:
        - "test_discount_application"
        - "test_bulk_discount_auto_applied"
        - "test_contractor_discount"
    
    edge_cases_dimensions:
      description: "Tests de casos límite de dimensiones"
      examples:
        - "test_minimum_dimensions"
        - "test_maximum_dimensions"
        - "test_invalid_dimensions_rejected"
    
    error_handling:
      description: "Tests de manejo de errores"
      examples:
        - "test_product_not_found"
        - "test_invalid_quantity"
        - "test_discount_over_limit"
    
    shopify_sync_verification:
      description: "Tests de sincronización con Shopify"
      examples:
        - "test_webhook_updates_kb"
        - "test_daily_reconciliation"
        - "test_price_mismatch_detection"
  
  critical_assertions:
    - "result['calculation_verified'] == True"
    - "len(validation['errors']) == 0"
    - "abs(calculated - expected) < 0.01"

# ==============================================================================
# MÉTRICAS DE MONITOREO EN PRODUCCIÓN
# ==============================================================================
monitoring:
  
  critical_metrics:
    calculation_verified_false:
      threshold: 0
      action: "ALERTA CRÍTICA inmediata"
      description: "Nunca debe ocurrir - indica que LLM calculó directamente"
    
    error_rate_schema_validation:
      threshold: "< 0.1%"
      action: "Revisar prompts de extracción"
      description: "Errores en extracción de parámetros por el LLM"
    
    price_out_of_range:
      threshold: "Auto-detectar"
      action: "Queue revisión humana"
      description: "Precio cotizado fuera de rango esperado"
    
    latency_p95:
      threshold: "< 3 segundos"
      action: "Optimizar o escalar"
      description: "Latencia del 95 percentil"
  
  alerting:
    channels:
      - slack
      - email
    escalation:
      - level: 1
        condition: "calculation_verified == False"
        action: "Page on-call engineer"
      - level: 2
        condition: "error_rate > 1%"
        action: "Notify team lead"

# ==============================================================================
# ESTIMACIONES DE COSTO Y RENDIMIENTO
# ==============================================================================
performance_estimates:
  
  cost_per_query:
    current_architecture: "$0.03-0.05 (multi-agent)"
    proposed_architecture: "$0.002-0.01 (hybrid)"
    reduction: "~70%"
  
  latency:
    current: "5-8 segundos"
    proposed: "1.5-3 segundos"
    improvement: "~60%"
  
  accuracy:
    current: "Variable (LLM calculates)"
    proposed: "100% (deterministic code)"
  
  kb_sync_time:
    current: "Manual"
    proposed: "Real-time (webhooks)"

# ==============================================================================
# ROADMAP DE MIGRACIÓN
# ==============================================================================
migration_roadmap:
  
  phase_1:
    name: "Fundación"
    duration: "Semana 1-2"
    tasks:
      - "Consolidar JSON KB a single source of truth"
      - "Implementar funciones de cálculo deterministas con tests"
      - "Configurar webhooks Shopify básicos"
  
  phase_2:
    name: "Agente Core"
    duration: "Semana 3-4"
    tasks:
      - "Migrar a LangGraph 1.0 con tool definitions"
      - "Configurar structured outputs para extracción de parámetros"
      - "Implementar verificación dual-path"
  
  phase_3:
    name: "Producción"
    duration: "Semana 5-6"
    tasks:
      - "Testing con golden dataset (50+ casos reales)"
      - "Configurar observabilidad (LangSmith/Langfuse)"
      - "Deploy gradual con shadow testing vs sistema actual"
  
  phase_4:
    name: "Optimización"
    duration: "Continuo"
    tasks:
      - "Evaluar Qdrant para búsqueda semántica si necesario"
      - "Optimizar model selection (GPT-4o-mini vs Gemini Flash)"
      - "Caching de consultas frecuentes"
