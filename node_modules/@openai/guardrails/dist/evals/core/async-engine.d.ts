/**
 * Async run engine for guardrail evaluation.
 *
 * This module provides an asynchronous engine for running guardrail checks on evaluation samples.
 * It supports batch processing, error handling, and progress reporting for large-scale evaluation workflows.
 */
import { Context, RunEngine, Sample, SampleResult } from './types';
import { ConfiguredGuardrail } from '../../runtime';
/**
 * Runs guardrail evaluations asynchronously.
 */
export declare class AsyncRunEngine implements RunEngine {
    private readonly guardrailNames;
    private readonly guardrails;
    private readonly multiTurn;
    constructor(guardrails: ConfiguredGuardrail[], multiTurn?: boolean);
    /**
     * Run evaluations on samples in batches.
     *
     * @param context - Evaluation context
     * @param samples - List of samples to evaluate
     * @param batchSize - Number of samples to process in parallel
     * @param desc - Description for the progress reporting
     * @returns List of evaluation results
     *
     * @throws {Error} If batchSize is less than 1
     */
    run(context: Context, samples: Sample[], batchSize: number, desc?: string): Promise<SampleResult[]>;
    /**
     * Evaluate a single sample against all guardrails.
     *
     * @param context - Evaluation context
     * @param sample - Sample to evaluate
     * @returns Evaluation result for the sample
     */
    private evaluateSample;
    private runGuardrailWithIncrementalSupport;
    private extractLatestUserPayload;
    private guardrailUsesConversationHistory;
    private runConversationGuardrailSinglePass;
    private runIncrementalConversationGuardrail;
    private extractLatestInput;
    private annotateIncrementalResult;
    private createConversationContext;
}
//# sourceMappingURL=async-engine.d.ts.map