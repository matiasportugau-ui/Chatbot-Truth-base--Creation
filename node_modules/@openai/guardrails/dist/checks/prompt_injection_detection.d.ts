/**
 * Prompt Injection Detection guardrail for detecting when tool calls or tool outputs
 * contain malicious instructions that are not aligned with the user's intent.
 *
 * This module provides a focused guardrail for detecting when LLM actions (tool calls,
 * tool call outputs) are not aligned with the user's goal. It parses conversation
 * history directly from OpenAI API calls, eliminating the need for external conversation tracking.
 *
 * The prompt injection detection check runs as both a preflight and output guardrail, checking only
 * tool_calls and tool_call_outputs, not user messages or assistant generated text.
 */
import { z } from 'zod';
import { CheckFn, GuardrailLLMContextWithHistory } from '../types';
/**
 * Configuration schema for the prompt injection detection guardrail.
 *
 * Extends the base LLM configuration with prompt injection detection-specific parameters.
 */
export declare const PromptInjectionDetectionConfig: z.ZodObject<{
    /** The LLM model to use for prompt injection detection analysis (e.g., "gpt-4.1-mini") */
    model: z.ZodString;
    /** Minimum confidence score (0.0 to 1.0) required to trigger the guardrail. Defaults to 0.7. */
    confidence_threshold: z.ZodDefault<z.ZodNumber>;
}, "strip", z.ZodTypeAny, {
    model: string;
    confidence_threshold: number;
}, {
    model: string;
    confidence_threshold?: number | undefined;
}>;
export type PromptInjectionDetectionConfig = z.infer<typeof PromptInjectionDetectionConfig>;
export declare const PromptInjectionDetectionConfigRequired: z.ZodObject<{
    model: z.ZodString;
    confidence_threshold: z.ZodNumber;
}, "strip", z.ZodTypeAny, {
    model: string;
    confidence_threshold: number;
}, {
    model: string;
    confidence_threshold: number;
}>;
/**
 * Context requirements for the prompt injection detection guardrail.
 *
 * Uses the extended context interface with conversation history methods.
 */
export type PromptInjectionDetectionContext = GuardrailLLMContextWithHistory;
/**
 * Output schema for prompt injection detection analysis.
 *
 * Extends the base LLM output with prompt injection detection-specific details.
 */
export declare const PromptInjectionDetectionOutput: z.ZodObject<{
    flagged: z.ZodBoolean;
    confidence: z.ZodNumber;
} & {
    /** What the LLM action is doing */
    observation: z.ZodString;
    /** Specific evidence from conversation demonstrating the injection (required if flagged=true, otherwise null) */
    evidence: z.ZodNullable<z.ZodString>;
}, "strip", z.ZodTypeAny, {
    flagged: boolean;
    confidence: number;
    observation: string;
    evidence: string | null;
}, {
    flagged: boolean;
    confidence: number;
    observation: string;
    evidence: string | null;
}>;
export type PromptInjectionDetectionOutput = z.infer<typeof PromptInjectionDetectionOutput>;
/**
 * Prompt injection detection check for function calls, outputs, and responses.
 */
export declare const promptInjectionDetectionCheck: CheckFn<PromptInjectionDetectionContext, string, PromptInjectionDetectionConfig>;
//# sourceMappingURL=prompt_injection_detection.d.ts.map