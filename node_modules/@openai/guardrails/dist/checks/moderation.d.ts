/**
 * Moderation guardrail for text content using OpenAI's moderation API.
 *
 * This module provides a guardrail for detecting harmful or policy-violating content
 * using OpenAI's moderation API. It supports filtering by specific content categories
 * and provides detailed analysis of detected violations.
 *
 * Configuration Parameters:
 * `categories` (Category[]): List of moderation categories to check.
 *
 * Available categories listed below. If not specified, all categories are checked by default.
 *
 * Example:
 * ```typescript
 * const cfg = { categories: ["hate", "harassment", "self-harm"] };
 * const result = await moderationCheck(null, "harmful content here", cfg);
 * console.log(result.tripwireTriggered); // true
 * ```
 */
import { z } from 'zod';
import { CheckFn } from '../types';
/**
 * Enumeration of supported moderation categories.
 *
 * These categories correspond to types of harmful or restricted content
 * recognized by the OpenAI moderation endpoint.
 */
export declare enum Category {
    SEXUAL = "sexual",
    SEXUAL_MINORS = "sexual/minors",
    HATE = "hate",
    HATE_THREATENING = "hate/threatening",
    HARASSMENT = "harassment",
    HARASSMENT_THREATENING = "harassment/threatening",
    SELF_HARM = "self-harm",
    SELF_HARM_INTENT = "self-harm/intent",
    SELF_HARM_INSTRUCTIONS = "self-harm/instructions",
    VIOLENCE = "violence",
    VIOLENCE_GRAPHIC = "violence/graphic",
    ILLICIT = "illicit",
    ILLICIT_VIOLENT = "illicit/violent"
}
/**
 * Configuration schema for the moderation guardrail.
 *
 * This configuration allows selection of specific moderation categories to check.
 * If no categories are specified, all supported categories will be checked.
 */
export declare const ModerationConfig: z.ZodObject<{
    /** List of moderation categories to check. Defaults to all categories if not specified. */
    categories: z.ZodDefault<z.ZodArray<z.ZodNativeEnum<typeof Category>, "many">>;
}, "strip", z.ZodTypeAny, {
    categories: Category[];
}, {
    categories?: Category[] | undefined;
}>;
export type ModerationConfig = z.infer<typeof ModerationConfig>;
export declare const ModerationConfigRequired: z.ZodEffects<z.ZodObject<{
    categories: z.ZodArray<z.ZodNativeEnum<typeof Category>, "many">;
}, "strip", z.ZodTypeAny, {
    categories: Category[];
}, {
    categories: Category[];
}>, {
    categories: Category[];
}, {
    categories: Category[];
}>;
/**
 * Context requirements for the moderation guardrail.
 */
export declare const ModerationContext: z.ZodObject<{
    /** Optional OpenAI client to reuse instead of creating a new one */
    guardrailLlm: z.ZodOptional<z.ZodUnknown>;
}, "strip", z.ZodTypeAny, {
    guardrailLlm?: unknown;
}, {
    guardrailLlm?: unknown;
}>;
export type ModerationContext = z.infer<typeof ModerationContext>;
/**
 * Guardrail check_fn to flag disallowed content categories using OpenAI moderation API.
 *
 * Calls the OpenAI moderation endpoint on input text and flags if any of the
 * configured categories are detected. Returns a result containing flagged
 * categories, details, and tripwire status.
 *
 * @param ctx Runtime context (unused)
 * @param data User or model text to analyze
 * @param config Moderation config specifying categories to flag
 * @returns GuardrailResult indicating if tripwire was triggered, and details of flagged categories
 */
export declare const moderationCheck: CheckFn<ModerationContext, string, ModerationConfig>;
//# sourceMappingURL=moderation.d.ts.map