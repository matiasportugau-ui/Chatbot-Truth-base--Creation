/**
 * Base client functionality for guardrails integration.
 *
 * This module contains the shared base class and data structures used by both
 * async and sync guardrails clients.
 */
import { OpenAI, AzureOpenAI } from 'openai';
import { GuardrailResult, GuardrailLLMContext, Message } from './types';
import { GuardrailBundle, ConfiguredGuardrail } from './runtime';
import { NormalizedConversationEntry } from './utils/conversation';
export type OpenAIResponseType = OpenAI.Completions.Completion | OpenAI.Chat.Completions.ChatCompletion | OpenAI.Chat.Completions.ChatCompletionChunk | OpenAI.Responses.Response;
/**
 * Organized guardrail results by pipeline stage.
 */
export interface GuardrailResults {
    preflight: GuardrailResult[];
    input: GuardrailResult[];
    output: GuardrailResult[];
    readonly allResults: GuardrailResult[];
    readonly tripwiresTriggered: boolean;
    readonly triggeredResults: GuardrailResult[];
}
/**
 * Extension of GuardrailResults with convenience methods.
 */
export declare class GuardrailResultsImpl implements GuardrailResults {
    preflight: GuardrailResult[];
    input: GuardrailResult[];
    output: GuardrailResult[];
    constructor(preflight: GuardrailResult[], input: GuardrailResult[], output: GuardrailResult[]);
    get allResults(): GuardrailResult[];
    get tripwiresTriggered(): boolean;
    get triggeredResults(): GuardrailResult[];
}
/**
 * Wrapper around any OpenAI response with guardrail results.
 */
export type GuardrailsResponse<T extends OpenAIResponseType = OpenAIResponseType> = T & {
    guardrail_results: GuardrailResults;
};
/**
 * Pipeline configuration structure.
 */
export interface PipelineConfig {
    version?: number;
    pre_flight?: GuardrailBundle;
    input?: GuardrailBundle;
    output?: GuardrailBundle;
}
/**
 * Stage guardrails mapping.
 */
export interface StageGuardrails {
    pre_flight: ConfiguredGuardrail[];
    input: ConfiguredGuardrail[];
    output: ConfiguredGuardrail[];
}
/**
 * Base class with shared functionality for guardrails clients.
 */
export declare abstract class GuardrailsBaseClient {
    protected pipeline: PipelineConfig;
    protected guardrails: StageGuardrails;
    protected context: GuardrailLLMContext;
    protected _resourceClient: OpenAI;
    raiseGuardrailErrors: boolean;
    /**
     * Extract the latest user text message from a conversation for text guardrails.
     *
     * This method specifically extracts text content from messages. For other content types,
     * create parallel methods like extractLatestUserImage() or extractLatestUserVideo().
     */
    extractLatestUserTextMessage(messages: Message[]): [string, number];
    protected createGuardrailsResponse<T extends OpenAIResponseType>(llmResponse: T, preflightResults: GuardrailResult[], inputResults: GuardrailResult[], outputResults: GuardrailResult[]): GuardrailsResponse<T>;
    protected setupGuardrails(config: string | PipelineConfig, context?: GuardrailLLMContext): Promise<void>;
    applyPreflightModifications(data: Message[] | string, preflightResults: GuardrailResult[]): Message[] | string;
    protected instantiateAllGuardrails(): Promise<StageGuardrails>;
    protected validateContext(context: GuardrailLLMContext): void;
    protected extractResponseText(response: OpenAIResponseType): string;
    protected loadPipelineBundles(config: string | PipelineConfig): Promise<PipelineConfig>;
    protected abstract createDefaultContext(): GuardrailLLMContext;
    initializeClient(config: string | PipelineConfig, openaiArgs: ConstructorParameters<typeof OpenAI>[0], clientClass: typeof OpenAI | typeof AzureOpenAI): Promise<void>;
    protected abstract overrideResources(): void;
    private shouldRunGuardrail;
    runStageGuardrails(stageName: 'pre_flight' | 'input' | 'output', text: string, conversationHistory?: unknown, suppressTripwire?: boolean, raiseGuardrailErrors?: boolean): Promise<GuardrailResult[]>;
    protected createContextWithConversation(conversationHistory: NormalizedConversationEntry[]): GuardrailLLMContext;
    protected appendLlmResponseToConversation(conversationHistory: NormalizedConversationEntry[] | string | null | undefined, llmResponse: OpenAIResponseType): NormalizedConversationEntry[];
    normalizeConversationHistory(payload: unknown): NormalizedConversationEntry[];
    loadConversationHistoryFromPreviousResponse(previousResponseId?: string | null): Promise<NormalizedConversationEntry[]>;
    private collectConversationItems;
    protected handleLlmResponse<T extends OpenAIResponseType>(llmResponse: T, preflightResults: GuardrailResult[], inputResults: GuardrailResult[], conversationHistory?: unknown, suppressTripwire?: boolean): Promise<GuardrailsResponse<T>>;
}
//# sourceMappingURL=base-client.d.ts.map