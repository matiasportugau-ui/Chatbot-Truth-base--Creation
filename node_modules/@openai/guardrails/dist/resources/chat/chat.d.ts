/**
 * Chat completions with guardrails.
 */
import { OpenAI } from 'openai';
import { GuardrailsBaseClient, GuardrailsResponse } from '../../base-client';
import { Message } from '../../types';
/**
 * Chat completions with guardrails.
 */
export declare class Chat {
    private client;
    constructor(client: GuardrailsBaseClient);
    get completions(): ChatCompletions;
}
/**
 * Chat completions interface with guardrails.
 */
export declare class ChatCompletions {
    private client;
    constructor(client: GuardrailsBaseClient);
    /**
     * Create chat completion with guardrails.
     *
     * Runs preflight first, then executes input guardrails concurrently with the LLM call.
     */
    create(params: {
        messages: Message[];
        model: string;
        stream: true;
        suppressTripwire?: boolean;
    } & Omit<OpenAI.Chat.Completions.ChatCompletionCreateParams, 'messages' | 'model' | 'stream'>): Promise<AsyncIterableIterator<GuardrailsResponse>>;
    create(params: {
        messages: Message[];
        model: string;
        stream?: false;
        suppressTripwire?: boolean;
    } & Omit<OpenAI.Chat.Completions.ChatCompletionCreateParams, 'messages' | 'model' | 'stream'>): Promise<GuardrailsResponse<OpenAI.Chat.Completions.ChatCompletion>>;
}
//# sourceMappingURL=chat.d.ts.map